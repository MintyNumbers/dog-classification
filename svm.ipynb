{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Klassifikation von Hunderassen mit SVMs\n",
    "Dieses Notebook nutzt zur Klassifizierung von Hunderassen eine Methode des klassischen maschinellen Lernens, die Support Vector Machine (SVM)."
   ],
   "id": "fda07f8ec35fc7ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Laden der Daten und Aufsplitten der Daten in Trainings- und Testdaten\n",
    "\n",
    "### Herunterladen der Daten\n",
    "\n",
    "Bevor das Notebook ausgeführt werden kann, muss der `Images`-Ordner des [Stanford Dog Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) heruntergeladen werden und im selben Verzeichnis wie dieses Notebook im Unterordner `dataset` gesichert werden. Die resultierende Dateistruktur sollte so aussehen (Ausschnitt):\n",
    "```\n",
    ".\n",
    "├── svm.ipynb\n",
    "├── dataset\n",
    "│   ├── Images\n",
    "│   │   ├── n02113799-standard_poodle\n",
    "│   │   ├── ...\n",
    "```\n",
    "\n",
    "Genau genommen genügen die `Images`-Unterordner\n",
    "\n",
    "- `n02113799-standard_poodle`\n",
    "- `n02113978-Mexican_hairless`\n",
    "- `n02115641-dingo`\n",
    "- `n02115913-dhole`\n",
    "- `n02116738-African_hunting_dog`\n",
    "\n",
    "da dies die fünf Rassen sind, die von der SVM klassifiziert werden sollen.\n",
    "\n",
    "### Splitting\n",
    "\n",
    "Da in jeder Klasse ausreichend Bilder zur Verfügung stehen, um Test- und Trainingsdaten bei der Kreuzvalidierung sínnvoll trennen zu können, ist dieser Vorverarbeitungsschritt prinzipiell nicht nötig. Dennoch soll an dieser Stelle gezeigt werden, wie mithilfe des eigens entwickelten Split-Helpers die Daten aufgetrennt werden.\n",
    "\n",
    "**Hinweis:** Dieser Schritt läuft nur dann ohne Fehler, wenn die Ordner `./dataset/Train` und `./dataset/Test` noch nicht existieren. So wird sichergestellt, dass die Daten nicht mehrfach in dieselben Ordner gesplittet werden und dadurch Duplikate entstehen. Um diese Fehler zu vermeiden, kann für nachfolgende Durchläufe die Variable `SPLIT_DATA` auf `False` gesetzt werden."
   ],
   "id": "dff7d97a9e4fc6ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helpers.split import train_test_split\n",
    "\n",
    "SPLIT_DATA = False  # Set True to create a data split (Make sure ./dataset/Test and ./dataset/Train directories do not exist)\n",
    "\n",
    "if SPLIT_DATA:\n",
    "    train_test_split()\n",
    "    print(\"\\n\\n --- Splitting done ---\")"
   ],
   "id": "7bb0b615897cf0e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Daneben steht im Helpers-Package auch die Funktion `load_dataset` zur Verfügung, mit der direkt aus dem `Images`-Ordner oder aus den vorbereiteten Trainings- und Test-Verzeichnissen die Bilder und zugehörigen Hunderassen eingelesen werden können. Dabei durchlaufen die Bilder eine Vorverarbeitung, in der sie auf standardmäßig 256x256 Pixel skaliert werden. Kleinere Bilder sowie die kürzeren Seiten nach der das Seitenverhältnis bewahrenden Skalierung werden schwarz aufgefüllt. Heraus kommt ein Tupel, mit den Bilddaten als `ndarray` und den Labels als `ndarray`. Für die SVM muss das Format der Labels allerdings noch angepasst werden, damit nicht mehr pro Klasse eine Komponente gesetzt wird. Standardmäßig entspricht das Label-Array vom Aufbau her nämlich der folgenden Tabelle (ohne Überschriften), die SVM erwartet allerdings einen Vektor (also 1xn statt 5xn).\n",
    "\n",
    "| Pudel | Mexican | Dingo | Dhole | African |\n",
    "|:------|:--------|:------|:------|:--------|\n",
    "| 1     | 0       | 0     | 0     | 0       |\n",
    "| 0     | 0       | 1     | 0     | 0       |\n",
    "| 0     | 1       | 0     | 0     | 0       |\n",
    "| 0     | 0       | 0     | 0     | 1       |\n",
    "| 0     | 0       | 0     | 1     | 0       |\n",
    "\n",
    "Da jedes Bild nur einer Hunderasse zugeordnet ist, die Indizes der Rassen sich nicht ändern und die einzige Spalte mit dem Maximalwert 1 jeweils die dem Bild zugeordnete Hunderasse ist, kann der Index mit dem maximalen Wert als Klassenlabel für die SVM verwendet werden."
   ],
   "id": "818c26e9fc23d1d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helpers.dataloader import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# load all (unsplitted) Image Data. Alternatively, change the path to use Train/Test splits\n",
    "train_img, train_label_matrix = load_dataset(\"./dataset/Train/Images\")\n",
    "test_img, test_label_matrix = load_dataset(\"./dataset/Test/Images\")\n",
    "images = np.concatenate((train_img, test_img))\n",
    "label_matrix = np.concatenate((train_label_matrix, test_label_matrix))\n",
    "\n",
    "# reformat labels\n",
    "labels = np.argmax(label_matrix, axis=1)\n",
    "print(labels)"
   ],
   "id": "c723c1382d9737c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Merkmalsextraktion\n",
    "\n",
    "Damit die SVM trainiert werden kann, müssen aus den Bildern relevante Features extrahiert werden. Im Folgenden werden diese kurz vorgestellt.\n",
    "\n",
    "### Körperform\n",
    "\n",
    "Um die Körper-/Kopfform des Hundes zu bestimmen, wird eine Hough-Transformation durchgeführt. Dafür werden die durchschnittlichen Radien und die Standardabweichung der 10 signifikantesten Kreise als Features gewählt, da sie Rückschlüsse darauf erlauben, ob der Hund eher rund oder kantig ist.\n",
    "Ebenfalls wird die Anzahl der Ecken als Merkmal für den Körperbau verwendet, um beispielsweise spitze oder runde Ohren besser auseinanderhalten zu können.\n",
    "\n",
    "### Fell\n",
    "\n",
    "Zur Erkennung, ob ein Hund Fell hat (wie ein Pudel) oder nicht (wie ein Mexican Hairless) wird ein empfindlich eingestellter Canny-Kantendetektor eingesetzt. Außerdem wird die Entropie des Bildes bestimmt, um über die \"Unruhe\" Rückschlüsse auf die Beschaffenheit des Fells zu ziehen.\n",
    "\n",
    "### Farbe\n",
    "\n",
    "Die Durchschnittsfarbe des Bilds, ein Grauwert- und ein RGB-Histogramm sollen dabei helfen, den Hund anhand der Fellfarbe zu identifizieren.\n",
    "\n",
    "### Ergebnis\n",
    "\n",
    "Das Modell wurde mit verschiedenen Kombinationen der Featurevektoren getestet, das beste Ergebnis basierend auf Genauigkeit und benötigter Verarbeitungszeit konnte durch die Verwendung von Grauwerthistogramm und Entropie erzielt werden. Daher sind nur diese Funktionen im Notebook enthalten. Die anderen, weniger nützlichen Featureextraktionen finden sich in `various_features.py`."
   ],
   "id": "1f14b0bc1c541e25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from skimage.measure import shannon_entropy\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "def extract_features_histogram(image, bins=32):\n",
    "    image = rgb2gray(image)\n",
    "    hist, _ = np.histogram(image, bins=bins, range=(0, 1))\n",
    "    return hist / hist.sum()  # Normalise\n",
    "\n",
    "\n",
    "def extract_image_entropy(image):\n",
    "    image = rgb2gray(image)\n",
    "    entropy_value = shannon_entropy(image)\n",
    "    return [entropy_value]"
   ],
   "id": "6b183c8dc2e4ca2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Anhand dieser Funktionen kann nun der Merkmalsvektor für ein Bild bestimmt werden. Das Bild soll an dieser Stelle bereits als `ndarray` vorhanden sein.",
   "id": "8834f9ae55e33445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_features(image):\n",
    "    fv = []\n",
    "    fv.extend(extract_features_histogram(image))\n",
    "    fv.extend(extract_image_entropy(image))\n",
    "    return fv"
   ],
   "id": "4d9b5b149fb312e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mit `extract_features` wird nun für jedes Bild der eingelesenen Daten der Merkmalsvektor berechnet. So ergibt sich aus `features` und `labels` das fertig vorbereitete Datenset für die SVM.",
   "id": "fbb0ef91544dcf21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "features = []\n",
    "for index, image in enumerate(images):\n",
    "    if index % 50 == 0:\n",
    "        print(\"Processing img\", index)\n",
    "    features.append(extract_features(image))"
   ],
   "id": "177c3a993421bc8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Merkmalsreduktion und Hyperparameteroptimierung\n",
    "\n",
    "Bei der Merkmalsreduktion werden die Verfahren PCA und LDA verglichen. Da das Training der SVM schnell geht, wird für beide Möglichkeiten eine Hyperparameteroptimierung vorgenommen und am Ende die jeweils beste Accuracy verglichen.\n",
    "\n",
    "Dafür werden zunächst Pipelines für die beiden Möglichkeiten angelegt, jeweils mit dem StandardScaler für die Merkmalsskalierung und einer SVM. Bei der SVM wird der Random State jeweils auf denselben Wert gesetzt, um vergleichbare Ergebnisse zu erhalten. Dadurch ist der einzige Unterschied die PCA bzw. LDA. Außerdem werden die Hyperparameterraster für die Hyperparameteroptimierung mit GridSearch definiert. Diese unterscheiden sich, damit für jede Pipeline die jeweils besten Hyperparameter ermittelt werden können. Über die Aufgabenstellung hinaus wurde auch die Anzahl der"
   ],
   "id": "b48f231f15894822"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Pipelines\n",
    "pipelines = {\n",
    "    'PCA': Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=5)),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", random_state=42))\n",
    "    ]),\n",
    "    'LDA': Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lda\", LDA()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", random_state=42))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Hyperparameter-Raster\n",
    "# C controls the margin tolerance of an SVM. Gamma defines the range of influence of a single data point\n",
    "# in the rbf kernel.\n",
    "param_grids = {\n",
    "    'PCA': {\n",
    "        \"svc__C\": [0.1, 1, 10, 100],\n",
    "        \"svc__gamma\": [0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    'LDA': {\n",
    "        \"svc__C\": [0.1, 1, 10, 100, 200],\n",
    "        \"svc__gamma\": [0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "}"
   ],
   "id": "c6d3381b85941c03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nach der Definition der grundlegenden Abläufe und Werte kann die eigentliche Hyperparameteroptimierung stattfinden. Dafür wird für jede Pipeline eine GridSearch mit 4-fold-Kreuzvalidierung durchgeführt und das beste Ergebnis zählt.",
   "id": "8458f0bff3317fb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_estimators = {}\n",
    "best_scores = {}\n",
    "\n",
    "for method, pipeline in pipelines.items():\n",
    "    print(f\"\\nStart training with {method} and hyperparameter optimisation...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[method],\n",
    "        scoring=\"accuracy\",\n",
    "        cv=4,  # 4-Fold Cross Validation\n",
    "        verbose=1,\n",
    "        n_jobs=-1,  # Parallelise the processing of the folds\n",
    "    )\n",
    "    grid_search.fit(features, labels)\n",
    "    best_estimators[method] = grid_search.best_estimator_\n",
    "    best_scores[method] = grid_search.best_score_\n",
    "    print(f\"\\nBest parameters for {method}: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross Validation Avg Accuracy for {method}: {grid_search.best_score_:.4f}\")"
   ],
   "id": "68a24df9aeae0310"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Das Ergebnis der Analyse zeigt, dass die PCA besser abschneidet. Der optimale Hyperparameter $C = 1$ weist darauf hin, dass die SVM versucht, eine \"weiche\" Trennlinie zwischen den Klassen zu ziehen - das ist aufgrund der schwierigen Trennbarkeit der Daten ein gutes Zeichen. Das moderat gewählte $\\gamma = 0.1$ ermöglicht es der SVM, auf Details einzugehen, ohne zu sehr ins Overfitting zu kommen.\n",
    "\n",
    "Das auf diese Weise gefundene beste Modell wird nun als optimiertes Modell weiterverwendet und einer finalen Kreuzvalidierung unterzogen (die dasselbe Ergebnis haben wird wie zuvor, sofern immer noch 4 folds verwendet werden), um konkrete Werte für den Vergleich mit dem als nächstes implementierten k-Nearest-Neighbour-Klassifikator zu erhalten."
   ],
   "id": "a5e586fb61ce50ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "optimised_model = best_estimators['PCA']\n",
    "\n",
    "cv_scores = cross_val_score(optimised_model, features, labels, cv=4, scoring=\"accuracy\")\n",
    "\n",
    "print(\"\\nResults of the Cross Validation:\")\n",
    "for fold_index, score in enumerate(cv_scores, 1):\n",
    "    print(f\"Fold {fold_index}: Accuracy = {score:.4f}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage Accuracy over all folds: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\"\n",
    ")"
   ],
   "id": "d518cf51702d248"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementierung des k-nearest-Neighbour-Klassifikators\n",
    "\n",
    "Zunächst wird der Klassifikator instanziiert und -- wie auch bei der SVM -- die Grid Search für die Hyperparameteroptimierung vorbereitet.\n",
    "Danach wird der Klassifikator mit den besten Parametern erneut kreuzvalidiert, um finale Ergebnisse für den Vergleich zu erhalten. Insgesamt ist der Prozess damit sehr ähnlich zur Erstellung und Hyperparameteroptimierung der SVM."
   ],
   "id": "11a297b336fe3d24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(metric=\"manhattan\", weights=\"distance\", n_jobs=-1)\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [1, 3, 5, 7, 9, 11, 13, 15],\n",
    "}\n",
    "\n",
    "# Hyperparameter Optimisation\n",
    "print(\"\\nStart training with k-NN and hyperparameter optimisation...\")\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=4,  # 4-Fold Cross Validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Parallelise processing\n",
    ")\n",
    "grid_search_knn.fit(features, labels)\n",
    "\n",
    "# Save the best model, parameters and values\n",
    "best_knn_model = grid_search_knn.best_estimator_\n",
    "best_knn_params = grid_search_knn.best_params_\n",
    "best_knn_score = grid_search_knn.best_score_\n",
    "\n",
    "# Print results of optimisation\n",
    "print(f\"\\nBest parameters for k-NN: {best_knn_params}\")\n",
    "print(f\"Best Cross Validation Avg Accuracy for k-NN: {best_knn_score:.4f}\")"
   ],
   "id": "fce60cbf7da0b5ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wie bereits bei der Hyperparameteroptimierung der SVM hat sich auch beim k-Nearest-Neighbour-Klassifikator ein moderater Wert als optimal herausgestellt: Mit $k = 13$ werden genügend Nachbarn miteinbezogen, um ausreichende Stabilität gegen Ausreißer zu bieten, ohne stark zu Overfitting zu neigen.",
   "id": "17c18563511b4df4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validate final model again (no different results expected than before when using 4 folds)\n",
    "cv_scores_knn = cross_val_score(\n",
    "    best_knn_model, features, labels, cv=4, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "print(\"\\nResults of the Cross Validation for k-NN:\")\n",
    "for fold_index, score in enumerate(cv_scores_knn, 1):\n",
    "    print(f\"Fold {fold_index}: Accuracy = {score:.4f}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage Accuracy over all folds: {cv_scores_knn.mean():.4f} ± {cv_scores_knn.std():.4f}\"\n",
    ")"
   ],
   "id": "5f68dd8cdf8d81f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vergleich der Ergebnisse von SVM und k-NN-Klassifikator\n",
    "\n",
    "Die SVM schneidet in der 4-fold-Kreuzvalidierung nach der Hyperparameteroptimierung mit einer durchschnittlichen Genauigkeit von 40,5 % etwas besser ab als der k-Nearest-Neighbour-Klassifikator (37,6 %)."
   ],
   "id": "2b5b3bd57744b3ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
